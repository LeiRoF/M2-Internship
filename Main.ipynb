{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from LRFutils import archive\n",
    "\n",
    "archive_path = archive.new()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loading Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one vector, we expect something like this:\n",
    "\n",
    "**Input $x_i$:**\n",
    "- I[x,y,f] : data cube of intensity for a given pixel (x,y) and frequency f\n",
    "\n",
    "**Outputs $y_i$:**\n",
    "- Vx[x,y,z] : data cube of velocity in x direction for a given coordinate in space (x,y,z)\n",
    "- Vy[x,y,z] : data cube of velocity in y direction for a given coordinate in space (x,y,z)\n",
    "- Vz[x,y,z] : data cube of velocity in z direction for a given coordinate in space (x,y,z)\n",
    "- $\\rho$[x,y,z] : data cube of density for a given coordinate in space (x,y,z)\n",
    "\n",
    "In practice, there is lot of vectors, so $x = [x_1, x_2, ..., x_N]$ and $y = [y_1, y_2, ..., y_N]$ where $N$ is the number of vectors.\n",
    "\n",
    "To simplify the neural network and potentially increase it's accuracy, we will not design a network that predicts all of the outputs at once. Instead, we will design 4 networks that will predict one output. This means that we will have 4 networks, one for each output. So $y_i$ will alternatively contain only one of the elements listed above.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **YOUR JOB**: In the following cell, write the code that load the data as specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> tuple[np.ndarray, tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Do what you want int this function, as long as it returns the following:\n",
    "    - list[3D-ndarray] : input vectors\n",
    "    - list[3D-ndarray] : output vectors\n",
    "    \"\"\"\n",
    "    x = [\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "    ]\n",
    "    y0 = [\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "    ]\n",
    "    y1 = [\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "    ]\n",
    "    y2 = [\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "    ]\n",
    "    y3 = [\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "        np.random.rand(10, 10, 3),\n",
    "    ]\n",
    "    return x, y0, y1, y2, y3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Post data treatment\n",
    "\n",
    "This part only consist to check the data consistency, normalize it and split the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification that the data are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y0, y1, y2, y3 = load_data()\n",
    "assert len(x) == len(y0) == len(y1) == len(y2) == len(y3), \"x and y must have the same length\"\n",
    "x = np.array(x)\n",
    "y0 = np.array(y0)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vectors = len(x)\n",
    "size_x = x[0].shape\n",
    "size_x_x, size_x_y, size_x_z = size_x\n",
    "channel_x = 1\n",
    "input_shape = (size_x_x, size_x_y, size_x_z, channel_x)\n",
    "\n",
    "size_y0 = y0[0].shape\n",
    "size_y0_x, size_y0_y, size_y0_z = size_y0\n",
    "channel_y0 = 1\n",
    "output0_shape = (size_y0_x, size_y0_y, size_y0_z, channel_y0)\n",
    "\n",
    "size_y1 = y1[0].shape\n",
    "size_y1_x, size_y1_y, size_y1_z = size_y1\n",
    "channel_y1 = 1\n",
    "output1_shape = (size_y1_x, size_y1_y, size_y1_z, channel_y1)\n",
    "\n",
    "size_y2 = y2[0].shape\n",
    "size_y2_x, size_y2_y, size_y2_z = size_y2\n",
    "channel_y2 = 1\n",
    "output2_shape = (size_y2_x, size_y2_y, size_y2_z, channel_y2)\n",
    "\n",
    "size_y3 = y3[0].shape\n",
    "size_y3_x, size_y3_y, size_y3_z = size_y3\n",
    "channel_y3 = 1\n",
    "output3_shape = (size_y3_x, size_y3_y, size_y3_z, channel_y3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= np.max(np.abs(x))\n",
    "y0 /= np.max(np.abs(y0))\n",
    "y1 /= np.max(np.abs(y1))\n",
    "y2 /= np.max(np.abs(y2))\n",
    "y3 /= np.max(np.abs(y3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_frac=0.2\n",
    "test_frac=0.1\n",
    "\n",
    "train_frac = 1 - valid_frac - test_frac\n",
    "\n",
    "train_x = x[:int(nb_vectors * train_frac)]\n",
    "train_y0 = y0[:int(nb_vectors * train_frac)]\n",
    "train_y1 = y1[:int(nb_vectors * train_frac)]\n",
    "train_y2 = y2[:int(nb_vectors * train_frac)]\n",
    "train_y3 = y3[:int(nb_vectors * train_frac)]\n",
    "train_y = [train_y0, train_y1, train_y2, train_y3]\n",
    "\n",
    "valid_x = x[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y0 = y0[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y1 = y1[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y2 = y2[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y3 = y3[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y = [valid_y0, valid_y1, valid_y2, valid_y3]\n",
    "\n",
    "test_x = x[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y0 = y0[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y1 = y1[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y2 = y2[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y3 = y3[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y = [test_y0, test_y1, test_y2, test_y3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 3D CNN model\n",
    "\n",
    "def get_model(input_shape, output_shape):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # model.add(tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='softmax'))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Reshape(output_shape))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y0\n",
    "\n",
    "model0 = get_model(input_shape, output0_shape)\n",
    "model0.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model0.fit(train_x, train_y0, epochs=10, batch_size=32, validation_data=(valid_x, valid_y0))\n",
    "model0.save('{archive_path}/model0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y1\n",
    "\n",
    "model1 = get_model(input_shape, output0_shape)\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(train_x, train_y1, epochs=10, batch_size=32, validation_data=(valid_x, valid_y1))\n",
    "model1.save('{archive_path}/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y2\n",
    "\n",
    "model2 = get_model(input_shape, output0_shape)\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(train_x, train_y2, epochs=10, batch_size=32, validation_data=(valid_x, valid_y2))\n",
    "model2.save('{archive_path}/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y3\n",
    "\n",
    "model3 = get_model(input_shape, output0_shape)\n",
    "model3.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(train_x, train_y3, epochs=10, batch_size=32, validation_data=(valid_x, valid_y3))\n",
    "model3.save('{archive_path}/model3.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model for y0\n",
    "\n",
    "score0 = model0.evaluate(test_x, test_y0, verbose=0)\n",
    "print('Test loss:', score0[0])\n",
    "print('Test accuracy:', score0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32394665479660034\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y1\n",
    "\n",
    "score1 = model1.evaluate(test_x, test_y1, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.21887971460819244\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y2\n",
    "\n",
    "score2 = model2.evaluate(test_x, test_y2, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.24905277788639069\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y3\n",
    "\n",
    "score3 = model3.evaluate(test_x, test_y3, verbose=0)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10, 3)\n",
      "(1, 10, 10, 3, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 10, 10, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_prediction = [x[0,...]]\n",
    "x_prediction = np.expand_dims(x_prediction, axis=-1)\n",
    "print(x_prediction.shape)\n",
    "\n",
    "y0_prediction = model0.predict(x_prediction)\n",
    "print(y0_prediction.shape)\n",
    "\n",
    "# y1_prediction = model1.predict([x_prediction])\n",
    "# print(y1_prediction.shape)\n",
    "\n",
    "# y2_prediction = model2.predict([x_prediction])\n",
    "# print(y2_prediction.shape)\n",
    "\n",
    "# y3_prediction = model3.predict([x_prediction])\n",
    "# print(y3_prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ebd3c877a0b17c24a089976ab492d87c18a36389aac1f17c74c28a388c2775d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
