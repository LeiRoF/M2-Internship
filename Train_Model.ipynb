{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.24.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from tensorflow) (44.1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (23.1.21)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.9/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.9/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in ./venv/lib/python3.9/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./venv/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (1.24.2)\n",
      "Requirement already satisfied: LRFutils==0.1.2 in ./venv/lib/python3.9/site-packages (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install LRFutils==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 10:59:54.309562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 10:59:54.733254: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-10 10:59:54.733290: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-10 10:59:56.695490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-10 10:59:56.695879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-10 10:59:56.695890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from LRFutils import archive\n",
    "import os\n",
    "\n",
    "archive_path = archive.new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: ligne 1: nvidia-smi : commande introuvable\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one vector, we expect something like this:\n",
    "\n",
    "**Input $x_i$:**\n",
    "- I[x,y,f] : data cube of intensity for a given pixel (x,y) and frequency f\n",
    "\n",
    "**Outputs $y_i$:**\n",
    "- Vx[x,y,z] : data cube of velocity in x direction for a given coordinate in space (x,y,z)\n",
    "- Vy[x,y,z] : data cube of velocity in y direction for a given coordinate in space (x,y,z)\n",
    "- Vz[x,y,z] : data cube of velocity in z direction for a given coordinate in space (x,y,z)\n",
    "- $\\rho$[x,y,z] : data cube of density for a given coordinate in space (x,y,z)\n",
    "\n",
    "In practice, there is lot of vectors, so $x = [x_1, x_2, ..., x_N]$ and $y = [y_1, y_2, ..., y_N]$ where $N$ is the number of vectors.\n",
    "\n",
    "To simplify the neural network and potentially increase it's accuracy, we will not design a network that predicts all of the outputs at once. Instead, we will design 4 networks that will predict one output. This means that we will have 4 networks, one for each output. So $y_i$ will alternatively contain only one of the elements listed above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **YOUR JOB**: In the following cell, write the code that load the data as specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> tuple[np.ndarray, tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Do what you want int this function, as long as it returns the following:\n",
    "    - list[3D-ndarray] : input vectors\n",
    "    - list[3D-ndarray] : output vectors\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y0 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "\n",
    "    window_size = 5\n",
    "\n",
    "    width = (window_size-1)//2\n",
    "\n",
    "    for file in os.listdir(\"dataset/all\")[0:1]:\n",
    "        print(file)\n",
    "        data = np.load(\"dataset/all/\" + file)\n",
    "\n",
    "        crop = np.arange(width, data[\"obs_datacube\"].shape[1]-width)\n",
    "        \n",
    "        for i in crop:\n",
    "            for j in crop:\n",
    "                x.append(data[\"obs_datacube\"][i-width:i+width+1, j-width:j+width+1, :])\n",
    "                y0.append(data[\"rho_datacube\"][i, j, :])\n",
    "                y1.append(data[\"vx_datacube\"][i, j, :])\n",
    "                y2.append(data[\"vy_datacube\"][i, j, :])\n",
    "\n",
    "    print(\"x shape: \", np.array(x).shape)\n",
    "    \n",
    "    return x, y0, y1, y2, y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Post data treatment\n",
    "\n",
    "This part only consist to check the data consistency, normalize it and split the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification that the data are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_643.npz\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "x, y0, y1, y2, y3 = load_data()\n",
    "assert len(x) == len(y0) == len(y1) == len(y2) == len(y3), \"x and y must have the same length\"\n",
    "x = np.array(x)\n",
    "y0 = np.array(y0)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vectors = len(x)\n",
    "size_x = x[0].shape\n",
    "size_x_x, size_x_y, size_x_z = size_x\n",
    "channel_x = 1\n",
    "input_shape = (size_x_x, size_x_y, size_x_z, channel_x)\n",
    "\n",
    "size_y0 = y0[0].shape\n",
    "size_y0_x, size_y0_y, size_y0_z = size_y0\n",
    "channel_y0 = 1\n",
    "output0_shape = (size_y0_x, size_y0_y, size_y0_z, channel_y0)\n",
    "\n",
    "size_y1 = y1[0].shape\n",
    "size_y1_x, size_y1_y, size_y1_z = size_y1\n",
    "channel_y1 = 1\n",
    "output1_shape = (size_y1_x, size_y1_y, size_y1_z, channel_y1)\n",
    "\n",
    "size_y2 = y2[0].shape\n",
    "size_y2_x, size_y2_y, size_y2_z = size_y2\n",
    "channel_y2 = 1\n",
    "output2_shape = (size_y2_x, size_y2_y, size_y2_z, channel_y2)\n",
    "\n",
    "size_y3 = y3[0].shape\n",
    "size_y3_x, size_y3_y, size_y3_z = size_y3\n",
    "channel_y3 = 1\n",
    "output3_shape = (size_y3_x, size_y3_y, size_y3_z, channel_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= np.max(np.abs(x))\n",
    "y0 /= np.max(np.abs(y0))\n",
    "y1 /= np.max(np.abs(y1))\n",
    "y2 /= np.max(np.abs(y2))\n",
    "y3 /= np.max(np.abs(y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_frac=0.2\n",
    "test_frac=0.1\n",
    "\n",
    "train_frac = 1 - valid_frac - test_frac\n",
    "\n",
    "train_x = x[:int(nb_vectors * train_frac)]\n",
    "train_y0 = y0[:int(nb_vectors * train_frac)]\n",
    "train_y1 = y1[:int(nb_vectors * train_frac)]\n",
    "train_y2 = y2[:int(nb_vectors * train_frac)]\n",
    "train_y3 = y3[:int(nb_vectors * train_frac)]\n",
    "train_y = [train_y0, train_y1, train_y2, train_y3]\n",
    "\n",
    "valid_x = x[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y0 = y0[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y1 = y1[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y2 = y2[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y3 = y3[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y = [valid_y0, valid_y1, valid_y2, valid_y3]\n",
    "\n",
    "test_x = x[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y0 = y0[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y1 = y1[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y2 = y2[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y3 = y3[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y = [test_y0, test_y1, test_y2, test_y3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 3D CNN model\n",
    "\n",
    "def get_model(input_shape, output_shape):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv3D(32, kernel_size=(15, 15, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(tf.keras.layers.Conv3D(64, kernel_size=(5, 5, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='softmax'))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Reshape(output_shape))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:02:18.819312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-10 11:02:18.820253: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-10 11:02:18.821232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cluster16): /proc/driver/nvidia/version does not exist\n",
      "2023-02-10 11:02:18.826197: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 11:02:19.104690: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 13632226197504 exceeds 10% of free system memory.\n",
      "2023-02-10 11:02:19.105816: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at stateless_random_ops_v2.cc:67 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[13000704,262144] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[13000704,262144] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Training model for y0\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model0 \u001b[39m=\u001b[39m get_model(input_shape, output0_shape)\n\u001b[1;32m      4\u001b[0m model0\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m model0\u001b[39m.\u001b[39mfit(train_x, train_y0, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_data\u001b[39m=\u001b[39m(valid_x, valid_y0))\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(input_shape, output_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# <\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten())\n\u001b[0;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49madd(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(np\u001b[39m.\u001b[39;49mprod(output_shape), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, kernel_initializer\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhe_uniform\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(np\u001b[39m.\u001b[39mprod(output_shape), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39madd(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(np\u001b[39m.\u001b[39mprod(output_shape), activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhe_uniform\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/M2-Prestel-state-from-obs-ML/venv/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/M2-Prestel-state-from-obs-ML/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/M2-Prestel-state-from-obs-ML/venv/lib/python3.9/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[13000704,262144] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "# Training model for y0\n",
    "\n",
    "model0 = get_model(input_shape, output0_shape)\n",
    "model0.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model0.fit(train_x, train_y0, epochs=10, batch_size=32, validation_data=(valid_x, valid_y0))\n",
    "model0.save(f'{archive_path}/model0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y1\n",
    "\n",
    "model1 = get_model(input_shape, output0_shape)\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(train_x, train_y1, epochs=10, batch_size=32, validation_data=(valid_x, valid_y1))\n",
    "model1.save(f'{archive_path}/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y2\n",
    "\n",
    "model2 = get_model(input_shape, output0_shape)\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(train_x, train_y2, epochs=10, batch_size=32, validation_data=(valid_x, valid_y2))\n",
    "model2.save(f'{archive_path}/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model for y3\n",
    "\n",
    "model3 = get_model(input_shape, output0_shape)\n",
    "model3.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(train_x, train_y3, epochs=10, batch_size=32, validation_data=(valid_x, valid_y3))\n",
    "model3.save(f'{archive_path}/model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model for y0\n",
    "\n",
    "score0 = model0.evaluate(test_x, test_y0, verbose=0)\n",
    "print('Test loss:', score0[0])\n",
    "print('Test accuracy:', score0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model for y1\n",
    "\n",
    "score1 = model1.evaluate(test_x, test_y1, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model for y2\n",
    "\n",
    "score2 = model2.evaluate(test_x, test_y2, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model for y3\n",
    "\n",
    "score3 = model3.evaluate(test_x, test_y3, verbose=0)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{archive_path}/scores.txt', 'w') as f:\n",
    "    f.write('\\t\\t\\t\\tModel 0\\tModel 1\\tModel 2\\tModel 3\\n')\n",
    "    f.write(f'Test loss:    \\t{round(score0[0],3)}\\t{round(score1[0],3)}\\t{round(score2[0],3)}\\t{round(score3[0],3)}\\n')\n",
    "    f.write(f'Test accuracy:\\t{round(score0[1],3)}\\t{round(score1[1],3)}\\t{round(score2[1],3)}\\t{round(score3[1],3)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "x_prediction = [x[0,...]]\n",
    "x_prediction = np.expand_dims(x_prediction, axis=-1)\n",
    "print(x_prediction.shape)\n",
    "\n",
    "y0_prediction = model0.predict(x_prediction)\n",
    "print(y0_prediction.shape)\n",
    "\n",
    "# y1_prediction = model1.predict([x_prediction])\n",
    "# print(y1_prediction.shape)\n",
    "\n",
    "# y2_prediction = model2.predict([x_prediction])\n",
    "# print(y2_prediction.shape)\n",
    "\n",
    "# y3_prediction = model3.predict([x_prediction])\n",
    "# print(y3_prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f3504165b11491f2f78d69ba41d30335901f7599302f48b3bfea9c0b8f9ae61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
