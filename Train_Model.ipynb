{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from LRFutils import archive\n",
    "\n",
    "archive_path = archive.new()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loading Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one vector, we expect something like this:\n",
    "\n",
    "**Input $x_i$:**\n",
    "- I[x,y,f] : data cube of intensity for a given pixel (x,y) and frequency f\n",
    "\n",
    "**Outputs $y_i$:**\n",
    "- Vx[x,y,z] : data cube of velocity in x direction for a given coordinate in space (x,y,z)\n",
    "- Vy[x,y,z] : data cube of velocity in y direction for a given coordinate in space (x,y,z)\n",
    "- Vz[x,y,z] : data cube of velocity in z direction for a given coordinate in space (x,y,z)\n",
    "- $\\rho$[x,y,z] : data cube of density for a given coordinate in space (x,y,z)\n",
    "\n",
    "In practice, there is lot of vectors, so $x = [x_1, x_2, ..., x_N]$ and $y = [y_1, y_2, ..., y_N]$ where $N$ is the number of vectors.\n",
    "\n",
    "To simplify the neural network and potentially increase it's accuracy, we will not design a network that predicts all of the outputs at once. Instead, we will design 4 networks that will predict one output. This means that we will have 4 networks, one for each output. So $y_i$ will alternatively contain only one of the elements listed above.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **YOUR JOB**: In the following cell, write the code that load the data as specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> tuple[np.ndarray, tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Do what you want int this function, as long as it returns the following:\n",
    "    - list[3D-ndarray] : input vectors\n",
    "    - list[3D-ndarray] : output vectors\n",
    "    \"\"\"\n",
    "    x = [\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "    ]\n",
    "    y0 = [\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "    ]\n",
    "    y1 = [\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "    ]\n",
    "    y2 = [\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "    ]\n",
    "    y3 = [\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "        np.random.rand(10, 10, 10),\n",
    "    ]\n",
    "    return x, y0, y1, y2, y3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Post data treatment\n",
    "\n",
    "This part only consist to check the data consistency, normalize it and split the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification that the data are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y0, y1, y2, y3 = load_data()\n",
    "assert len(x) == len(y0) == len(y1) == len(y2) == len(y3), \"x and y must have the same length\"\n",
    "x = np.array(x)\n",
    "y0 = np.array(y0)\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vectors = len(x)\n",
    "size_x = x[0].shape\n",
    "size_x_x, size_x_y, size_x_z = size_x\n",
    "channel_x = 1\n",
    "input_shape = (size_x_x, size_x_y, size_x_z, channel_x)\n",
    "\n",
    "size_y0 = y0[0].shape\n",
    "size_y0_x, size_y0_y, size_y0_z = size_y0\n",
    "channel_y0 = 1\n",
    "output0_shape = (size_y0_x, size_y0_y, size_y0_z, channel_y0)\n",
    "\n",
    "size_y1 = y1[0].shape\n",
    "size_y1_x, size_y1_y, size_y1_z = size_y1\n",
    "channel_y1 = 1\n",
    "output1_shape = (size_y1_x, size_y1_y, size_y1_z, channel_y1)\n",
    "\n",
    "size_y2 = y2[0].shape\n",
    "size_y2_x, size_y2_y, size_y2_z = size_y2\n",
    "channel_y2 = 1\n",
    "output2_shape = (size_y2_x, size_y2_y, size_y2_z, channel_y2)\n",
    "\n",
    "size_y3 = y3[0].shape\n",
    "size_y3_x, size_y3_y, size_y3_z = size_y3\n",
    "channel_y3 = 1\n",
    "output3_shape = (size_y3_x, size_y3_y, size_y3_z, channel_y3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "x /= np.max(np.abs(x))\n",
    "y0 /= np.max(np.abs(y0))\n",
    "y1 /= np.max(np.abs(y1))\n",
    "y2 /= np.max(np.abs(y2))\n",
    "y3 /= np.max(np.abs(y3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_frac=0.2\n",
    "test_frac=0.1\n",
    "\n",
    "train_frac = 1 - valid_frac - test_frac\n",
    "\n",
    "train_x = x[:int(nb_vectors * train_frac)]\n",
    "train_y0 = y0[:int(nb_vectors * train_frac)]\n",
    "train_y1 = y1[:int(nb_vectors * train_frac)]\n",
    "train_y2 = y2[:int(nb_vectors * train_frac)]\n",
    "train_y3 = y3[:int(nb_vectors * train_frac)]\n",
    "train_y = [train_y0, train_y1, train_y2, train_y3]\n",
    "\n",
    "valid_x = x[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y0 = y0[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y1 = y1[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y2 = y2[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y3 = y3[int(nb_vectors * train_frac):int(nb_vectors * (train_frac + valid_frac))]\n",
    "valid_y = [valid_y0, valid_y1, valid_y2, valid_y3]\n",
    "\n",
    "test_x = x[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y0 = y0[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y1 = y1[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y2 = y2[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y3 = y3[int(nb_vectors * (train_frac + valid_frac)):]\n",
    "test_y = [test_y0, test_y1, test_y2, test_y3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 3D CNN model\n",
    "\n",
    "def get_model(input_shape, output_shape):\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # model.add(tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='relu', kernel_initializer='he_uniform'))\n",
    "    # > Utile ?\n",
    "    # model.add(tf.keras.layers.Dense(np.prod(output_shape), activation='softmax'))\n",
    "    # <\n",
    "    model.add(tf.keras.layers.Reshape(output_shape))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.3767 - accuracy: 0.0000e+00 - val_loss: 4.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 4.5323 - accuracy: 0.0000e+00 - val_loss: 0.8557 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.9239 - accuracy: 0.0000e+00 - val_loss: 0.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5015 - accuracy: 0.0000e+00 - val_loss: 0.2953 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3087 - accuracy: 0.0000e+00 - val_loss: 0.2740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2743 - accuracy: 0.0000e+00 - val_loss: 0.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2652 - accuracy: 0.0000e+00 - val_loss: 0.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2634 - accuracy: 0.0000e+00 - val_loss: 0.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2531 - accuracy: 0.0000e+00 - val_loss: 0.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2589 - accuracy: 0.0000e+00 - val_loss: 0.2496 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training model for y0\n",
    "\n",
    "model0 = get_model(input_shape, output0_shape)\n",
    "model0.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model0.fit(train_x, train_y0, epochs=10, batch_size=32, validation_data=(valid_x, valid_y0))\n",
    "model0.save(f'{archive_path}/model0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 769ms/step - loss: 0.3516 - accuracy: 0.0000e+00 - val_loss: 3.5075 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.9024 - accuracy: 1.4286e-04 - val_loss: 0.9622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0408 - accuracy: 0.0000e+00 - val_loss: 0.4678 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5038 - accuracy: 0.0000e+00 - val_loss: 0.2901 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2953 - accuracy: 0.0000e+00 - val_loss: 0.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2624 - accuracy: 0.0000e+00 - val_loss: 0.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2539 - accuracy: 0.0000e+00 - val_loss: 0.2583 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2506 - accuracy: 0.0000e+00 - val_loss: 0.2529 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2473 - accuracy: 0.0000e+00 - val_loss: 0.2488 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2432 - accuracy: 0.0000e+00 - val_loss: 0.2459 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training model for y1\n",
    "\n",
    "model1 = get_model(input_shape, output0_shape)\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(train_x, train_y1, epochs=10, batch_size=32, validation_data=(valid_x, valid_y1))\n",
    "model1.save(f'{archive_path}/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3686 - accuracy: 0.0000e+00 - val_loss: 2.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 2.8579 - accuracy: 0.0000e+00 - val_loss: 0.7301 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.7747 - accuracy: 0.0000e+00 - val_loss: 0.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.4650 - accuracy: 0.0000e+00 - val_loss: 0.2798 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2859 - accuracy: 1.4286e-04 - val_loss: 0.2583 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2574 - accuracy: 1.4286e-04 - val_loss: 0.2565 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2548 - accuracy: 1.4286e-04 - val_loss: 0.2476 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2465 - accuracy: 0.0000e+00 - val_loss: 0.2478 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2437 - accuracy: 0.0000e+00 - val_loss: 0.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2367 - accuracy: 0.0000e+00 - val_loss: 0.2436 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training model for y2\n",
    "\n",
    "model2 = get_model(input_shape, output0_shape)\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(train_x, train_y2, epochs=10, batch_size=32, validation_data=(valid_x, valid_y2))\n",
    "model2.save(f'{archive_path}/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.3374 - accuracy: 0.0000e+00 - val_loss: 3.3661 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.5839 - accuracy: 1.4286e-04 - val_loss: 0.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6309 - accuracy: 1.4286e-04 - val_loss: 0.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3624 - accuracy: 0.0000e+00 - val_loss: 0.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2718 - accuracy: 0.0000e+00 - val_loss: 0.2676 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2650 - accuracy: 0.0000e+00 - val_loss: 0.2649 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2607 - accuracy: 0.0000e+00 - val_loss: 0.2602 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2561 - accuracy: 0.0000e+00 - val_loss: 0.2582 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2524 - accuracy: 0.0000e+00 - val_loss: 0.2545 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2485 - accuracy: 0.0000e+00 - val_loss: 0.2522 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training model for y3\n",
    "\n",
    "model3 = get_model(input_shape, output0_shape)\n",
    "model3.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(train_x, train_y3, epochs=10, batch_size=32, validation_data=(valid_x, valid_y3))\n",
    "model3.save(f'{archive_path}/model3.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2488040328025818\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y0\n",
    "\n",
    "score0 = model0.evaluate(test_x, test_y0, verbose=0)\n",
    "print('Test loss:', score0[0])\n",
    "print('Test accuracy:', score0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.25017374753952026\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y1\n",
    "\n",
    "score1 = model1.evaluate(test_x, test_y1, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23982952535152435\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y2\n",
    "\n",
    "score2 = model2.evaluate(test_x, test_y2, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2535218596458435\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model for y3\n",
    "\n",
    "score3 = model3.evaluate(test_x, test_y3, verbose=0)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{archive_path}/scores.txt', 'w') as f:\n",
    "    f.write('\\t\\t\\t\\tModel 0\\tModel 1\\tModel 2\\tModel 3\\n')\n",
    "    f.write(f'Test loss:    \\t{round(score0[0],3)}\\t{round(score1[0],3)}\\t{round(score2[0],3)}\\t{round(score3[0],3)}\\n')\n",
    "    f.write(f'Test accuracy:\\t{round(score0[1],3)}\\t{round(score1[1],3)}\\t{round(score2[1],3)}\\t{round(score3[1],3)}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 10, 10)\n",
      "(1, 10, 10, 10, 1)\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "(1, 10, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x_prediction = [x[0,...]]\n",
    "x_prediction = np.expand_dims(x_prediction, axis=-1)\n",
    "print(x_prediction.shape)\n",
    "\n",
    "y0_prediction = model0.predict(x_prediction)\n",
    "print(y0_prediction.shape)\n",
    "\n",
    "# y1_prediction = model1.predict([x_prediction])\n",
    "# print(y1_prediction.shape)\n",
    "\n",
    "# y2_prediction = model2.predict([x_prediction])\n",
    "# print(y2_prediction.shape)\n",
    "\n",
    "# y3_prediction = model3.predict([x_prediction])\n",
    "# print(y3_prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ebd3c877a0b17c24a089976ab492d87c18a36389aac1f17c74c28a388c2775d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
